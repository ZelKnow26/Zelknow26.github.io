---
layout: post
title: 操作系统
author: ZelKnow26
tagline: "真难"
date: 2018.07.15 20:16:12
categories: other
tag: other
---

太难啦。

# 复习
##1 计算机系统概述

### 基础知识
计算机的四个结构化部件：
- 处理器：数据处理
- 内存：存储数据和程序，易失
- 输入/输出模块：计算机和外部环境间移动数据
- 系统总线：上述三部件提供通信

处理器：
- 程序计数器（PC）
- 指令寄存器（IR）
- 和存储器交换数据：
	- 存储器地址寄存器（MAR）：确定下一次读写的存储器地址
	- 存储器缓冲寄存器（MBR）：存放写入存储器或读取到的存储器数据。
- 和输入/输出交换数据：
	- 输入/输出地址寄存器（I/O AR）：用于确定特定的输入/输出设备
	- 输入/输出缓冲寄存器（I/O BR）：用于在输入/输出和处理器间交换数据。

指令周期
- 取指阶段：PC保存着下一次要取的指令的地址，一般递增。指令保存在IR中。
- 执行阶段

指令可分为四类，可组合：
- 处理器-存储器
- 处理器-I/O
- 数据处理：算术逻辑操作
- 控制：改变执行顺序，指定下一条指令地址。

### 中断

I/O、存储器中断处理器正常处理过程的机制。例如在I/O设备进行打印的时候处理器去处理别的程序，然后I/O设备打印完之后中断处理器让处理器来处理I/O打印完成后的工作。

流程
1. 设备发送中断信号
2. 处理器停止当前指令执行
3. 处理器发送确认信号
4. 将当前程序的程序状态字（PSW）和当前程序地址（PC）压入系统控制栈
5. 将中断处理程序入口地址装入程序计数器，开始下一指令周期，控制转移到中断处理程序
6. 将除了PSW和PC以外所有寄存器的信息压入控制栈中，以便恢复
7. 处理中断
8. 被保存的寄存器从栈中释放并恢复。
9. 恢复PSW和PC的值

多个中断
- 处理中断时禁止发生中断，挂起中断（没考虑优先级和时间限制）
- 定义中断优先级，允许高优先级中断打断低优先级的中断

### 存储器

#### 多级存储器 
高级的存储器速度快，处理器访问次数多的数据会从低级的存储器转移到高级的存储器中。（局部性原理）

#### 高速缓存
高速缓存由C个存储槽，每个存储槽有K个字，每个槽有一个标签代表这个槽存储哪一个块，一般是这个块的地址的较高的若干相同位。读时先查看寻的地址是否位于高速缓存中，若不存在则将含有该地址数据的块传入高速缓存中。

高速缓存涉及以下问题：
- 高速缓存大小：适当小的高速缓存可以对性能产生显著影响
- 块大小：过大的话移出的数据可能用到，过小的话局部性原理体现不出
- 映射函数：越灵活，就越可能可以增大命中率的置换算法；但也可能会使实现的逻辑电路越复杂
- 置换算法：将访问可能性最小的块移除
- 写策略：何时将修改内容写回内存（每次修改时或块被替换时）
- 级数

###I/O

- 可编程I/O：处理器给I/O发命令来执行I/O指令。这样不必中断处理器，但需要定期检查I/O的状态以确定是否完成。通常需要等待很长时间，不断询问状态，严重降低性能。
- 中断驱动I/O：发送I/O命令，然后处理器去做别的工作，I/O处理完后，中断处理器进行数据传送。比可编程I/O更有效，但仍需管理I/O与存储器间的所有数据传送

两种形式缺陷：
1. 传送速度受限于处理器
2. 处理器忙于管理传送I/O的工作，必须执行很多指令。

#### 直接内存存取（DMA）
当处理器需要读写一块数据时，给DMA模块发送命令，包含：
- 是否请求读写
- 涉及的I/O设备地址
- 开始读写的存储器单元
- 读写的字数
然后委托DMA管理，处理完后DMA中断处理器。这样仅有开始和结束时处理器参与。
DMA需要控制总线，因此处理要使用总线时必须等待DMA模块，导致执行速度变慢（注意不是中断），但效率仍比上述两者高。

### 多处理器
提供并行处理能力

#### 对称多处理器（SMP）
特点：两个及以上处理器共享内存和I/O设备，可连接到相同I/O设备，可执行相同功能，且由一个操作系统控制

优势：性能好（并行工作）、可用性好（单个处理器失效不导致停机）、渐增式成长（通过增加处理器提高性能）、可伸缩性（通过配置不同处理器数量来提供不同性能价格的产品）

##2 操作系统概述
操作系统是控制应用程序执行的程序，并充当应用程序和计算机硬件之间的接口。
三个目标：
- 方便：使计算机易于使用
- 有效：更有效地使用计算机系统资源
- 扩展能力：允许引进新的系统功能

####作为用户/计算机接口

操作系统提供以下服务：程序开发、程序运行、I/O设备访问、文件访问控制、系统访问、错误检测和响应、记账（监控）

计算机系统中三种重要接口：
- 指令系统体系结构（ISA）：计算机遵循的机器语言指令系统，是硬件和软件的分界线
- 应用程序二进制接口（ABI）：定义了二进制可移植性标准，操作系统的系统调用接口和通过ISA能使用的硬件资源和服务
- 应用程序编程接口（API）：允许应用程序访问系统的硬件资源和服务，由用户级ISA和HLL库调用提供。

####作为资源管理器
计算机就是一组资源，操作系统负责管理计算机的软硬件资源，进而控制计算机
与其他控制机制的不同点：与普通软件相同，都是处理器执行的一组程序，但操统经常放弃控制，且必须依赖处理器才能重获控制。

####易扩展性
应能不断发展：适应硬件升级和新型硬件出现、新的服务、修正错误

###操作系统的发展
定义：是一组程序的集合，控制和管理计算机软硬件资源，合理地对各种作业进行调度，方便用户使用计算机系统
功能：管理资源、运行程序

####串行
程序员顺序访问计算机
缺点：人工调度问题（固定时间分配）、准备时间长
提高串行效率的方法：开发出用作公用软件的各种系统软件，函数库、链接器、加载器、调试器、I/O驱动程序

####批处理系统
使用监控程序，自动作业序列
监控程序控制事件的顺序。它每次从输入设备读取一个作业放到用户程序区域，控制权交给作业，完成后返回监控程序，读取下一个。

需要的硬件支持：
- 内存保护（保护监控程序）
- 计时器（防止作业独占系统）
- 特权指令（只能由监控程序执行）
- 中断（使操作系统放弃/获得控制权更灵活）

操作模式：（由内存保护和特权指令引入）
- 用户态：不能访问受保护区域，不能执行特权指令
- 内核态：可以访问受保护区域，可以执行特权指令

单道程序批处理中处理器必须等到I/O指令结束才能继续。

####多道程序批处理
为了提高I/O速度，表现为多个作业同时进入主存，切换运行
需要的功能：
- I/O中断（硬件）
- DMA（硬件）
- 内存管理（软件）
- 作业调度（软件）

####分时系统
为了满足用户与计算机的交互需要，减少响应时间
多个交互作业，多个用户分享处理器时间
把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用

####实时系统
用于专用系统，进行实时控制与实时信息处理，强调即时响应和高可靠性，以在规定时间内完成对事件的处理为特征

当代操作系统同时具有分时、实时和多道批处理功能，成为通用操作系统。

###操作系统的主要成就
####进程
一个正在执行的程序。

三个组成部分：
- 一段可执行的程序
- 程序所需要的相关数据（变量、工作空间、缓冲区等）
- 程序执行的上下文环境/进程状态

####内存管理
职责：
- 进程隔离（防止相互干涉各自的存储空间）
- 自动分配和管理（需要时动态分配，对程序员透明）
- 支持模块化程序设计（如面向对象）
- 保护和访问控制（访问共享存储空间可能引发问题）
- 长期存储（非易失，磁盘文件系统）

####信息保护与安全
可用性、保密性、数据完整性和认证

####调度与资源管理
- 公平性（平等对待同类进程）
- 有差别的响应性（区分不同服务要求的不同作业类型）
- 有效性（在最大吞吐量、最小响应时间和尽可能多用户之间找到平衡）

###现代操作系统的特征
####微内核
内核是操作系统中实现基本功能的代码，它常驻内存并运行于特权方式。
- 单体内核/宏内核/分层内核：内核实现操作系统的所有基本功能，一般用一个进程实现，效率高，但难于修改和扩充
- 微内核：内核只实现最基本功能，更多的功能代码组织为多个进程，运行在内核之外，各自独立使用自己的地址空间，运行于非特权方式，客户/服务器模式，设计简单灵活，适用于嵌入式与分布式环境，但效率稍低
- 混合内核：微内核与宏内核的结合

####多线程
线程是分派CPU的最小工作单位
进程是分派系统资源(CPU除外)的最小单位，由一个或多个线程实现其功能
多线程技术即是把进程划分为同时进行的多个线程，适用于执行许多独立不需串行处理的应用程序。

####对称多处理器

####分布式与面向对象设计
分布式操作系统：分布式硬件环境，提供统一的资源管理
面向对象：为小内核系统提供模块扩展性，方便分布式工具和分布式OS的开发

####虚拟机与虚拟化
令本来只能运行一个操作系统的计算机可以同时运行多个操作系统，或一个操作系统的多个会话。每个VM具有特定操作系统的特征，有些VM还可具有特定硬件平台的特征

虚拟机监视程序（VMM）运行在宿主操作系统之上，处理各个操作系统、存储介质、网络之间的通信，将处理器的控制权交给虚拟机中的操作系统。各个操作系统通过虚拟网络连接来相互通信。它是可编程的、对其上的软件是透明的、且可有效地利用其下的硬件

##进程描述与控制
###进程的概念
####程序的顺序执行
一个具有独立功能的程序独占处理机直至最终结束的过程
特征：
- 顺序性：只有前面的操作结束，才能执行后续操作
- 封闭性：独占全机资源，不受外界影响
- 可再现性：结果与速度无关
符合冯诺伊曼体系结构的要求

####程序的并发执行
指一组在逻辑上互相独立的程序或程序段在执行过程中，其执行时间在宏观上互相重叠，一个程序段的执行尚未结束，另一个程序段的执行已经开始的这种执行方式
不符合冯诺伊曼体系结构的要求

两种情形：
- 多道程序的并发执行
- 单道程序的程序段并发执行

特征：
- 间断性
- 失去封闭性
- 不可再现性

好处：充分利用系统资源，提高系统处理能力
坏处：破坏了计算机冯·诺依曼体系结构的顺序执行特性，引起一系列难解决的问题（互斥、同步、死锁、饥饿）

####进程特征
- 动态性：有一定的生命周期
- 并发性：多个进程实体，同时存在于内存中，能在一段时间内（不一定是同一时刻）同时运行
- 独立性：进程实体是一个能独立运行的基本单位，同时也是系统中独立获得资源和独立调度的基本单位
- 异步性：进程按各自独立的、不可预知的速度向前推进，即多个进程按异步方式运行
- 结构特征：进程实体是由程序段、数据段及进程控制块等部分组成----进程映像

####进程控制块
用于描述进程、管理与调度进程
- 标识符
- 状态（运行/就绪/等待）
- 优先级
- 程序计数器（PC）
- 内存指针
- 上下文数据（中断时处理器寄存器的数据）
- I/O状态信息
- 记账信息

###进程状态
两状态：运行态、未运行态

进程创建：交互登录、OS提供服务、进程派生
进程终止：halt或调用终止、退出系统、结束应用程序、错误和故障

五状态：新建、就绪、运行、阻塞、退出

####进程挂起
进程映像整体或部分从主存转移到辅存或相反
原因：
- 实存不足
- CPU时间浪费：例如很多进程等待I/O
- 调度策略：其他作业没有主存空间，不能运行

交换：
- 主存中无就绪态
- 把主存中某进程部分或全部移到磁盘----挂起
- 将挂起队列中的一个进程移入主存
- 交换是一种I/O操作，过于频繁可能导致性能恶化

不能从运行态挂起，从非运行态挂起，从内存调出外存

请看六/七态模型图03/21

特点：
- 不可立即执行
- 可能在等待一个事件
- 可通过代理挂起进程，这样只能通过代理显式命令操作系统才可转换状态

导致挂起的原因
- 交换（释放内存）
- 交互式用户请求（调试）
- 定时
- 父进程请求

###进程描述
进程映像：进程的物理表示
- 用户程序
- 用户数据
- 系统栈
- 进程控制块（PCB）

进程属性：
- 进程标识信息
	- 进程标识符
	- 父进程标识符
	- 用户标识符
- 处理器状态信息
	- 用户可见寄存器
	- 控制和状态寄存器
	- 栈指针（指向栈顶）
- 进程控制信息
	- 调度和状态信息（状态、优先级、等待的事件）
	- 数据结构
	- 进程间通信
	- 进程特权
	- 存储管理
	- 资源所有权和使用情况

####进程控制块的组织
- 链表：同状态进程的PCB成同一链表（就绪链表、阻塞链表），进程调度中的排队结构即用此方式实现
- 索引表：同状态进程的PCB成同一索引表（就绪索引表、阻塞索引表）

####PCB作用
是OS最重要的数据结构，涉及进程调度、资源分配、中断处理、性能监控和分析

###进程控制
完成进程的创建、撤销、进程的状态转换（进程切换/调度）
由原语完成

####原语
由若干指令构成，在系统模式下执行，用于完成一定功能的进程
是一种广义指令，相当于扩充的机器指令集
是一种原子操作，即，是不可分割的，操作中的所有动作必须一起做完

####执行模式
- 特权指令：不允许用户使用，仅允许OS使用
- 非特权指令

- 用户模式：只能执行非特权指令，执行用户程序
- 系统模式/内核模式：能执行指令全集，能改变CPU执行状态，操作系统在系统模式下运行

####内核
OS中包含重要系统功能的部分，驻留内存，在系统模式下运行，响应进程调用和设备中断
功能：
- 进程管理：创建、撤销、调度、切换
- 存储管理：分配空间、交换
- I/O管理：缓冲区，分配I/O
- 支持功能：中断处理

####执行模式切换
用户到系统：通过中断
系统到用户：修改PSW程序状态字

####进程创建与撤销
创建原语：
- 分配进程标识号
- 分配空间（进程映像）
- 初始化进程控制块
- 设置链接
- 创建或扩充其他数据结构
撤销原语：
- 撤销所有子进程
- 回收进程占用的资源
- 撤销PCB

####进程切换
指定一个进程为运行态，并将CPU控制权交给该进程
时机：当OS从运行的进程获得控制权时

导致OS获得控制权：
- 中断：时钟中断、I/O中断、内存失效
- 陷阱/异常
- 系统调用：用户进程置为阻塞
只有通过软/硬或内/外中断，OS才能获得控制权

CPU响应系统中断时从用户模式切换到内核模式，使中断代码可执行特权指令
中断引发模式切换，但不一定引发进程切换

###OS的执行
- 非进程内核：OS代码是在特权模式下工作的独立实体
- 在用户进程中执行：OS是用户进程调用的例程，执行OS需切换到系统模式（不需进程切换）
- 基于进程的OS：主要内核被组织成独立进程，适合多处理器多机环境

###安全问题
####系统访问威胁
入侵者、恶意软件

####对抗措施
- 入侵检测
- 用户认证
- 访问控制
- 防火墙

##线程
###概念
一个进程内的基本调度单位

没有线程概念的系统中：
进程是资源分配、调度/执行的单位
造成主要问题：
- 进程切换开销大（切换要保存和恢复所有信息）
- 进程占用资源多（同类进程占据多份资源）

####多线程
指OS支持在一个进程中执行多个线程的能力

进程/任务：资源分配和保护的单位
- 拥有用于保存进程映像的虚地址空间
- 受保护地访问处理器、其他进程、文件和I/O资源

线程：分派的执行单位
- 执行状态
- 保存的线程上下文（非运行时）
- 一个执行栈
- 独立用来存储局部变量的静态存储空间
- 对进程的内存和其他资源的访问（与进程内的其他线程共享）

线程优点：
- 共享进程的代码、数据和资源
- 创建、终止速度快
- 切换时间少
- 通信效率高（无需调用OS内核，可利用共享的存储空间）

线程应用：
若应用程序可以按功能划分为不同小段，或可划分为一组相关的执行实体，用一组线程可以提高执行效率

###线程的功能特性
线程状态：运行、就绪、阻塞
线程不拥有资源，且进程与所有线程共享代码。但线程拥有自己的寄存器上下文和栈空间，用于储存局部变量和调用参数。

挂起、终止是进程级的概念，所有线程一起行动

线程状态操作：
- 派生
- 阻塞
- 唤醒/解除阻塞
- 调度（将就绪线程调度到处理器中执行）
- 结束

####线程同步
同一进程中的多线程共享同一地址空间和其他资源
需要对各个线程活动进行同步，以便它们互不干涉且不破坏数据结构

###线程分类
用户级线程与内核级线程
####用户级线程ULT
- 线程管理由应用程序完成
- 内核不知道线程的存在
- 优点
	- 线程切换不需要模式切换
	- 调度算法可在应用程序1专用
	- 不需要内核支持，可在任意OS上运行
- 缺点
	- 一个线程阻塞会导致整个进程阻塞
	- 不能利用多核和多处理器技术

进程阻塞，运行中的线程阻塞
进程就绪，阻塞的线程就绪

####内核级进程KLT
- 线程管理由内核完成
- 调度基于线程进行
- 优点
	- 线程阻塞不会导致进程阻塞
	- 可以利用多核和多处理器技术
	- 内核例程本身也可以使用多线程
- 缺点
	- 线程切换需要模式切换

组合：m个ULT映射到n（<=m）个KLT

####线程库
为程序员提供创建和管理线程的API

###多核与多线程
####阿姆德尔定律

$加速比=\frac{单处理器上程序运行时间}{在N个并行处理器上程序的运行时间}=\frac{1}{(1-f)+\frac{f}{N}}$
其中：N为处理器核数，f为本质上运行的代码所占百分比

####多线程设计中的关键问题
- 同时的并发进程/线程
- 调度：避免多处理器调度冲突
- 同步：控制共享资源的访问
- 存储器管理
- 可靠性与容错

####微内核
分层内核，所有功能按层次组织，只在相邻层之间发生交互
缺点：
- 一层的变化会对相邻层中的代码产生巨大影响
- 相邻层之间有很多交互，难以保证安全性

特点：垂直分层、客户/服务器结构（C/S）

优点：
- 一致接口：所有服务以消息形式提供
- 可扩展性：可增加新服务
- 灵活性：可增删功能
- 可移植性：只需要对内核修改即可将系统移植到新处理器上
- 可靠性：模块化设计、小的内核易被测试
- 分布式系统支持：消息传送不需知道目标机器的位置
- 对面向对象操作系统的支持：组件是具有明确定义接口的对象，可互连构造软件

低级存储器管理
微内核控制地址空间，只负责将每个虚页映射到一个物理页框上，内核外实现页替换算法等分页工作，例如虚页掉入、页换出等

三种微内核操作
- 授权：一个地址空间的所有者可以授权另一个进程使用它的某些页
- 映射：一个进程可以把它的页映射到另一个进程的地址空间，使两个进程者都可访问这些页
- 刷新：进程可以回收授权给其他进程或映射到另一个进程的任何页

####进程间的通信
*消息*是进程间通信的基本形式，由消息头和消息体构成
*端口*是发往某个特定进程的消息序列
*消息传递*是指将消息从一个进程的地址空间内复制到另一个进程的地址空间（速度远低于处理器）效率比共享存储方案低

微内核结构中，硬件中断当作消息处理，微内核识别中断，但可以不处理，将消息发给用户进程，让它处理中断


##并发：互斥与同步
###相关术语
原子操作：不可分割
临界区：不允许多个进程同时进入的一段访问共享资源的代码
死锁：两个及以上进程，因每个进程都在等待其他进程做完某事，不能继续执行
活锁：两个及以上进程，为响应其他进程中的变化，不断改变自己的状态，但是没有做任何有用的工作
互斥：当一个进程在临界区访问共享资源时，不允许其他进程进入访问
竞争条件：多个进程/线程读写共享数据，其结果依赖于它们执行的相对速度
饥饿：可运行的进程长期未被调度执行

####并发
并发：在同一时间间隔内发生的进程或线程，在此期间，它们可能交替地共享相同的资源
异步性：相对执行速度不可预测是多道程序系统的基本特征

影响进程执行速度的因素：
- 其他进程的活动
- OS处理中断的方式
- OS的调度策略

存在的问题：
- 全局资源的共享充满危险
- OS对资源的分配的管理难以达到最优
- 调试程序设计错误非常困难（不可再现）

####竞争条件
- 在并发环境中发生
- 多个进程共享数据
- 多个进程读取且至少一个进程写入
- 共享数据的最终结果取决于进程执行的相对速度

####OS必须考虑的问题
- 并发环境中跟踪每个进程，知道他们的状态
- 为每个进程分配和回收各种资源（管理资源）
	- 处理机（进程调度）
	- 存储器（内存管理）
	- 文件（文件系统）
	- I/O设备（I/O管理）
- 保护进程拥有的数据和物理资源
- 保证进程的结果与相对执行速度无关

####进程的竞争现象
- 特点
	- 不知道彼此存在
	- 需要访问相同资源（时钟、CPU、I/O）
	- 之间没有信息交换的需求
- 影响
	- 执行结果不受影响
	- 执行时间受影响
- 引发的控制问题
	- 互斥
	- 死锁
	- 饥饿

####互斥
多个进程需要访问一个不可共享的资源时，任何时候只能有一个访问这个资源
临界资源：不可共享的资源
临界区：访问临界资源的代码
死锁：一组进程中，每个进程都在无限等待该组进程中另一进程所占用的资源
饥饿：一组进程中，某个或某些进程无限等待该组进程中其他进程所占用的资源

####进程间通过共享的合作
- 特点
	- 没有意识到其他进程存在，但要维护数据完整性
	- 共享变量、文件或数据库等
- 相互产生的影响
	- 结果可能受影响
	- 时间受影响
- 引发的控制问题
	- 互斥
	- 死锁
	- 饥饿
	- 数据一致性

####进程间通过通信的合作
- 特点
	- 进程直接知道合作伙伴
	- 采用消息传送的方式通信（收发消息）
- 相互产生的影响：
	- 结果可能受影响
	- 时间受影响
- 引发的控制问题
	- 死锁
	- 饥饿

####互斥的要求
- 在具有相同资源或共享对象的临界区所有进程中，一次仅允许一个进程进入临界区（强制排他）
- 一个在非临界区停止的进程不干涉其他进程（充分并发）
- 没有进程在临界区中时，任何需要访问临界区的进程必须能立即进入（空闲让进）
- 不允许出现一个需要访问临界区的进程被无限延迟（有限等待）
- 相关进程的执行速度和处理机数目没有任何要求或限制（满足异步）
- 当进程不能进入临界区，应该立即释放处理机，防止进程忙等待（让权等待）

####实现互斥的方法
- 两进程轮流进入临界区
	- 可以保证互斥
	- 存在问题：
		- 忙等待：为了等待一事件的发生，反复测试该事件是否发生，浪费CPU时间
		- 必须轮流进入临界区：不合理，限制推进速度
		- 如果一个进程失败，另一个将被永远阻塞
	- 结论：难以支持并发处理

- 各自有自己的钥匙
	- 两进程反复检查对方的钥匙，若检测到对方钥匙为0，则将自己的钥匙设置为1，进入临界区，退出后将自己的钥匙设置为0。
	- 存在问题
		- 一进程在临界区内失败，另一进程永远阻塞
		- 不能保证互斥

- 将设置自己钥匙这一过程提到循环之前
	- 先表示自己想进入临界区，再检查对方是否进入
	- 可以保证互斥
	- 可能导致死锁（两进程都坚持进入）

- 在循环中先将钥匙设置为0，等一会，设置为1
	- 等一会，给其他进程进入的机会
	- 可以保证互斥
	- 会导致活锁

- Dekker算法
	- 定义一个turn，P0若turn==1时等待，退出缓冲区后turn=0
	- 避免无原则礼让
	- 规定各进程进入临界区顺序
	- flag表示互斥进程位置
	- turn解决同时发生的冲突
	- 存在问题
		- 逻辑复杂
		- 正确性难证明
		- 存在轮流问题
		- 存在忙等待

- Peterson算法
	- 先设turn=别人，只有当turn==别人和flag[别人]同时为真时才等待
	- 简单出色

####硬件实现方法
关中断
- 单CPU体系结构
- 如果进程访问临界资源时不被中断，就能保证互斥访问
- 途径
	- 使用开关中断指令
	- x86的开关指令为CLI/STI
- 缺点
	- 限制处理器交替执行各进程的能力
	- 不能用于多处理器结构

####专用指令
- 适用范围
	- 单处理器或共享主存多[核]处理器
	- 对同一存储单元的访问是互斥的
- 软件算法第二种尝试失败原因
	- 若测flag[1]和置flag[0]在同一指令周期完成就不会出错

- 比较和交换指令
	- 原子指令
	- 检测内存单元是否与测试值相等，若相等则用新值代替该值。
	- 返回旧内存单元的值

- TestSet指令
	- 比较交换指令的bool特例。
	- 若传入值为0，则置传入值为1，返回true，否则返回false

- exchange指令
	- 交换值
	- 令所有进程的key值为1，bolt值为0，若想进入临界区，交换bolt和keyi，测试keyi，若为0则进入，1不进入，这样其他进程进不去。

####机器指令方法优缺点
- 优点
	- 适用于单处理器或共享主存多[核]处理器系统，进程数目任意
	- 简单且易于证明
	- 可以使用多个变量支持多个临界区
- 缺点
	- 忙等待/自旋等待
	- 可能饥饿
	- 可能死锁

###常用并发机制
信号量：用于进程间传递信号的一个整数值，只有初始化、增、减三种原子操作，可阻塞/解除阻塞进程
二元信号量：取值为0和1的信号量
互斥量：似二元信号量，但要求为其加锁和解锁的为同一进程

###信号量
####信号量的操作
- 初始化：通常是将信号量的值初始化为非负整数（=可用资源数）
- P操作/semWait操作/Down操作
	- 信号量的值减一
	- 若信号量的值变成负数，则执行P操作的进程阻塞
- V操作/semSignal操作/Up操作
	- 信号量的值加1
	- 若信号量的值不是正数（绝对值=现被阻塞的进程数[等待队列的长度]），则使一个因执行P操作被阻塞的进程解除阻塞
- 此外，没有其他检查和修改信号量值的操作

####强弱信号量
强信号量：进出队列的顺序为FIFO，保证不会饥饿
弱信号量：没有保证进程从队列移出的顺序，不能保证不会饥饿

####信号量的实现
要保证P和V操作的原子性，以保证信号量操作的互斥
- 软件方案
	- Dekker算法
	- Peterson算法
- 硬件支持方案
	- TS指令
	- 关中断

####信号量的优缺点
- 优点
	- 简单表达能力强
	- PV操作可解决多种类型的同步互斥问题
- 缺点
	- 不够安全，会产生死锁
	- 遇到复杂同步互斥问题时实现复杂

###信号量的应用

####互斥
将初始设为1。
V操作时若s<=0将一个被阻塞进程置为就绪态

####同步
指系统中的一些进程需要相互合作，共同完成一项任务。具体说，就是一个进程运行到某点时需要另外一个进程为它提供消息，否则处于阻塞态，直到获得消息后唤醒
05P61

05P65？

###管程（不懂）
- 动机
	- 同步机制和同步策略的分离是灵活的，同时也是危险的
	- 集中管理（分装）以策安全
- 管程是一种封装同步机制与同步策略的程序设计语言结构
- 特点
	- 本地变量只能由管程过程访问（封装）
	- 进程通过调用管程过程进入管程（调用）
	- 每次只能一个进程在执行相关管程的过程（互斥）
- 主要缺陷
	- 可能增加了两次多余的进程切换
	- 对进程调度有特殊要求

###消息传递
- 进程交互的两个基本要求
	- 同步：互斥过程间需同步，同步指对进程执行时序的约束，包括对互斥与时序的先后限制
	- 通信：合作进程间交换信息
- 消息传递
	- 进程通信的一种常用方法
	- 适用范围广，多核、SMP、分布式
	- 由原语提供功能：
		- send(目的,信息)
		- receive(源,信息)
	- 实现形式多种

####消息传递的同步
- 隐含了同步：只有当进程发送消息后，接收者才收到消息
- 调用send原语后两种结果
	- 发送者进程被阻塞，直到消息被接收
	- 发送者进程不被阻塞
- 调用receive原语后两种可能结果
	- 接收者进程接受消息时，消息已发出，接收者不阻塞
	- 接收者进程接受消息时，消息未发出，接收者被阻塞，知道发送者发出消息

####三种组合方式
- 消息传递实现的三种常用组合方式
	- 阻塞send，阻塞receive方式，即“会合”原则，适用于进程间紧密同步（打电话）
	- 无阻塞send，阻塞receive，最有用的组合（收发短信）
	- 无阻塞send，阻塞receive，不要求任一方等待（贴/看小广告）
- 无阻塞send是最自然的选择，但错误可能会导致进程重复传递消息，消耗系统资源。且必须使用应答消息以证实收到消息
- 阻塞receive是常用的选择，但若消息丢失或发送进程失效，接收者进程长期阻塞

####消息传递的寻址
- send原语中指明接收者是必要的
- receive原语也指明发送者
- 直接寻址方案
	- 发送者在发送时给出了接收者进程的具体标识号，如进程ID
- 间接寻址方案
	- 发送者将消息发送到共享的信箱中临时保管，接收者从信箱中获得消息
	- 耦合方式：“一对一”，“多对一”，“一对多”或“多对多”
	- 进程与信箱的关联：静态方式（端口）和动态方式

####消息格式
- 取决于运行环境
	- 单机系统
	- 分布式系统
- 两类格式
	- 定长格式
	- 变长格式
- 消息格式
	- 消息头——消息类型、目标ID、源ID、消息长度、控制信息
	- 消息体——消息内容

####排队原则
- 先进先出（FIFO）原则
- 优先级原则

####应用
实现互斥P82
实现生产消费P83

###读者-写者问题（看一下）
- 同步与并发机制设计
- 问题描述：有一个多个进程共享的数据区，有一些只读取这个数据区的进程（reader）和一些只往数据区中写数据的进程（writer）
- 必须满足下列条件
	- 任意多的读进程可以同时读这个数据区
	- 一次只有一个写进程可以往数据区写
	- 如果一个写进程正在写，禁止任何读进程读数据区

####实现方法
- 读者优先信号量方案 P85
- 写者优先信号量方案 P86
- 基于消息传递的信号量方案 P87

##并发：死锁与饥饿
###死锁
一个进程集合中的每个进程都在等待只能由该集合中的其他一个进程才能引发的事件（释放占有资源/进行某项操作）
死锁是多个进程因竞争资源且推进顺序不合理而造成的一种僵局，若无外力作用，这些进程将永远不能再向前推进

###联合进程图
- 一种记录进程共享资源历史和分析死锁的工具
- 二个进程的联合进程图是一个二维网格，三个进程的联合进程图是一个三维网格
- 四种区域
	- 安全区域（白）
	- 敏感区域（黑）
	- 死锁区域（黑）
	- 不可达区域（彩）

####可重用资源
- 资源分类
	- 可重用资源与可消费资源
	- 可剥夺资源（处理机、内存）与不可剥夺资源（打印机、表、队列）
	- 永久性资源与临时性资源
- 可重用资源
	- 一次只能供一个进程安全使用，不会由于使用而耗尽资源
	- 可以获得、使用和释放，能再次被使用
	- 处理器、I/O通道、主存与辅存、设备、文件、数据库、信号量等数据结构
- 可消费资源
	- 可以创建（生产）并且可以销毁（消费）的资源
	- 数目没有限制，当一个进程得到一个可消费资源时，这个资源就不存在了
	- 中断、信号、消息、I/O缓冲区的信息

####资源分配图
用有向图描述的进程死锁模型
表示法：
- 资源类：方框
- 资源实例：黑圆点
- 进程：圆圈加进程名
- 分配边：资源实例指向进程的一条有向边
- 申请边：进程指向资源类的一条有向边

####死锁定理
- 如果资源分配图中没有环路，则系统中没有死锁，如果图中存在环路则系统中可能存在死锁
- 如果每个资源类中只包含一个资源实例，则环路是死锁存在的充分必要条件

####死锁的条件
死锁的三个必要条件
- 互斥条件
	- 指进程对所分配的资源进行拍他性使用，即在一段时间内某资源只由一个进程占有
	- 如果此时还有其他进程要求该资源，要求者只能阻塞，直至该资源的进程用毕释放
- 占有且等待条件
	- 进程已经占有至少一个资源，但可以提出新的资源请求
	- 若该资源已被其他进程占有，则请求进程阻塞，同时对已经获得的其它资源保持不放
- 不可剥夺/抢占条件
	- 进程已获得的资源在未使用完前不能被剥夺，只能在用完时自己释放
- 环路等待条件
	- 资源分配图中存在环路，即进程集合{P0,P1,P2,Pn}(n>=2)中P0等待P1占用的资源，P1等待P2占用的资源，......，Pn等待P0占用的资源
- 死锁的充分必要条件
	- 互斥
	- 占有且等待
	- 不可抢占
	- 循环等待

###死锁预防
- 四类方法
	- 鸵鸟算法：对死锁视而不见
	- 预防死锁
	- 避免死锁
	- 检测死锁
- 死锁预防：通过破坏死锁产生的四个条件中的一个或多个条件，保证不会发生死锁

####破坏互斥条件
- 方法：允许多个进程同时使用资源
- 适用条件
	- 资源的固有特性允许多个进程同时使用（如文件允许多个进程同时读）
	- 借助特殊技术允许多个进程同时使用（如打印机借助Spooling技术）
- 缺点：不适用于绝大多数资源

####破坏占有且等待条件
- 方法：禁止已拥有资源的进程再申请其它资源，如要求所有进程在一开始一次性申请在整个运行过程中所需的全部资源；活在申请资源要先释放其占有的资源后，再一次性申请所需全部资源
- 优点：简单、易于实现、安全
- 缺点：
	- 进程延迟进行
	- 资源严重浪费

####破坏不可剥夺条件
- 方法：
	- 一个已经占有了某些资源的进程，当它再提出新的资源请求而不能立即满足时，必须释放它已占有的所有资源，待以后需要时重新申请
	- OS可以剥夺一个进程占有的资源，分配给其他进程
- 适用条件：资源的状态可以很容易地保存和恢复（CPU）
- 缺点：实现复杂、代价大、反复申请/释放资源、系统开销大、降低系统吞吐量

####破坏环路等待条件
- 方法：
	- 要求每个进程任何时刻只能占有一个资源，如果要申请第二个则必须先释放第一个（不现实）
	- 对所有资源按类型进行线性排队，进程申请资源必须严格按照资源序号递增的顺序（可避免循环等待）
- 缺点：
	- 很难找到每个人满意的编号次序，类型序号的安排只能考虑一般作业的情况，限制用户简单自主编程
	- 易造成资源浪费（会不必要地拒绝对资源的访问）
	- 可能低效（使进程执行速度变慢）

###死锁避免
不需要事先采取限制措施破坏死锁条件，而是在资源动态分配过程中，采用某种策略防止系统进入不安全状态，避免发生死锁
- 不启动其资源请求会导致死锁的进程
- 不允许会导致死锁的进程资源请求

####进程启动拒绝
- 模型
	- n个进程和m种资源
	- 系统资源总量向量$R=(R_1,R_2,...,R_m)$，$R_j$为第j种资源的总数
	- 系统当前可用资源总量向量$V=(V_1,V_2,...,V_m)$，$V_j$为第j种资源的剩余数
	- 进程-资源需求矩阵C，$C_{ij}$=进程i与资源j的请求数
	- 进程-资源分配矩阵A，$A_{ij}$=当前已经分配给进程i的资源j数

####资源分配拒绝
Dijkstra受银行资金借贷管理的启发于1965年提出的
- 模型
	- 系统状态：由资源总量向量$R=(R_1,R_2,...,R_m)$、系统可用资源总量向量$V=(V_1,V_2,...,V_m)$、进程-资源需求矩阵C和进程-资源分配矩阵A表示
	- 安全状态：至少存在一个执行时序，使当前所有进程都能运行在结束状态
	- 不安全状态：不存在一个执行时序，使当前所有进程都能运行到结束状态

不安全状态举例？？？？？？？
- 只要系统处于安全状态，必定不会死锁
- 不安全状态不一定为死锁状态，但不能保证不会进入死锁
- 死锁避免的实质：如何使系统不进入不安全状态
	- 如果一个新进程的资源请求会导致不安全状态，拒绝启动这个进程
	- 如果满足一个进程新提出的一项资源请求后，会导致不安全状态，则拒绝分配资源给这个进程

银行家算法！！！！！！！！！！

####死锁避免优缺点
- 优点：
	- 比死锁预防限制少
	- 无需死锁检测中的资源剥夺和进程重启
- 缺点：
	- 必须事先声明每个进程请求的最大资源
	- 考虑的进程必须是无关的，即它们的执行顺序没有任何同步要求的限制
	- 分配的资源数目必须是固定的
	- 在占有资源时不能退出

###死锁检测
- 没有任何预先限制措施（死锁预防）
- 资源分配时不检查系统是否会进入不安全状态
- 系统可能出现死锁
- 系统检测是否出现死锁
- 死锁发生时进行恢复

####死锁检测时机和算法
- 检测时机
	- 资源申请时（早期检测，算法相对简单，但处理机时间消耗大）
	- 周期性检测，或死锁好像发生（CPU使用率降低到一定阈值时）
- 检测方法
	- 单个资源实例：检测资源分配图中是否存在环路
	- 多个资源实例：类似银行家算法的安全检查	

####恢复
- 剥夺法
	- 连续剥夺资源直到不再存在死锁
- 回退法
	- 每个死锁进程回滚到前面定义的某些检查点，重新启动所有进程（死锁可能会重现）
- 杀死进程法
	- 杀死所有死锁进程
	- 或连续杀死死锁进程直到不再存在死锁
	- 或杀死一个非死锁进程
杀死和剥夺要考虑代价

###综合死锁策略
- 把资源分成几组不同的资源类
- 为预防在资源类之间由于循环等待产生死锁，可使用线性排序策略
- 在一个资源类中，使用该类资源最合适的算法

###哲学家就餐问题
- 死锁与饥饿的经典问题----5个哲学家思考+吃意大利面，每个人必须用两把叉子吃，但总共有5把叉子
- 饥饿----一组进程中，某个或某些进程无限等待该组进程中其他进程所占用的资源

##内存
####存储体系
- 层次结构
	- 高速缓存：KB-MB级
	- 内存
	- SSD
	- 磁盘/外存
- 内存
	- 系统区：存放OS
	- 用户区：存放用户程序和数据

####存储管理的任务
将程序载入内存以让CPU执行
- 目的
	- 将内存区域进行划分以容纳多个进程（多道程序设计）
	- 有效分配内存以容纳尽可能多的进程

###存储管理的要求
####重定位
- 逻辑地址/相对地址
	- 逻辑地址：与内存内容无关的内存位置
	- 相对地址：相对于某一点（通常是程序起始位置，也可能是段基址）的逻辑地址（如偏移地址）
- 物理地址/绝对地址：内存的实际地址
- 多道程序和共享内存技术要求程序使用相对地址以支持重定位
	- 程序员不知道程序在运行时在内存所处的位置
	- 处于内存某一块区域的程序代码，在运行中可能被交换出到外存，后来又被交换进到内存另一块区域
- 重定位一般要求一定的硬件支持

####保护
- 多道程序和共享内存技术要求一个进程不能对其他进程进行有意或无意的非授权访问
- 程序的内存引用只能在时检查
	- 重定位导致无法在编译时检查绝对地址
	- 多数程序设计语言允许地址的动态计算（如数组下标、指向某种数据结构的指针等）
	- 通常整合在重定位硬件机制中（从软件上，难以预计所有非法情况，开销也太大）

####共享
- 支持不同进程访问内存的同一区域
- 可能情形
	- 同一程序的不同进程实例共享程序区
	- 合作进程间共享某些数据结构
- 重定位机制通常也支持共享

####逻辑组织
- 物理上看，主存和辅存通常是一维线性结构的
- 反映程序组织的逻辑性，采用某种模块化形式组织用户程序及数据
	- 模块化有利于设计期间的编程
	- 模块化有利于运行时刻的保护
	- 模块化有利于运行时刻的共享
- 分段存储管理技术最符合用户（程序员）组织程序的观点

####物理组织
- 主存与辅存间的信息交换能更好地实现系统目标
- 程序猿关心物理组织是不切实际的
	- 主存有限致使程序员采用覆盖技术，浪费程序员经历和时间
	- 多道程序环境中，程序员编写代码时无法预知可用主存的数量和位置
- 物理组织是OS的责任（资源管理）

####覆盖技术和交换技术
- 在多道环境下扩充内存的方法
- 覆盖技术主要用在早期的操作系统中
- 交换技术被广泛用于小型分时系统中，交换技术的发展导致了虚存技术的出现
- 共同点：
	- 进程的程序和数据主要放在外存
	- 只有当前需要执行的部分才放在内存
	- 内外存之间进行信息交换

####覆盖技术
- 把程序划分为若干功能上相对独立的程序段，按照其自身的逻辑结构，让那些不会同时执行的程序段共享一块内存区域
- 程序员要向系统提供覆盖结构，然后由操作系统完成程序段之间的覆盖

####交换技术
- 交换技术
	- 当内存空间紧张时，系统将内存中某些进程暂时移到外存，把外存的某些进程换进内存，占据前者原来所占用的区域
	- 交换技术其实是进程在内存与外存之间的动态调度
- 与覆盖技术比较
	- 交换技术不要求内存给出程序段之间的逻辑覆盖结构
	- 交换发生在不同的进程或作业之间，而覆盖发生在同一进程或作业之内
	- 覆盖只能覆盖那些与覆盖段无关的程序段

###分区存储管理技术
- 分区
	- 包括固定分区和动态分区
	- 只在一些特殊场合使用（如内核存储管理）
	- 在一些已过时的操作系统中采用
- 简单内存分页（不单独使用）----大小相等，需一次装入一个进程的所有页
- 简单进程分段（不单独使用）----需一次装入一个进程的所有段
- 虚拟内存分页----不需一次装入一进程的所有页
- 虚拟内存分段----不需一次装入一进程的所有段

####固定分区
- 将内存划分成若干固定大小区域
	- 等长
	- 不等长
- 等长分区：任何小于或等于分区大小的进程都可以全部载入某一可用分区中（无可用分区时，可以应用交换技术）
- 等长分区存在问题
	- 若进程大于分区，则只能部分载入，要应用覆盖技术
	- 小进程将产生内部碎片，导致内存利用率降低
- 不等长分区：在一定程度上减缓了等长分区存在的问题（仍没有完全解决）

####固定分区的放置算法
- 等长分区的放置算法
	- 进程可以放到任意一个可用分区中
- 不等长分区的放置算法
	- 多队列：为每个分区设立一个输入队列，各个队列中的进程只能使用对应的分区----某些队列为空时会造成内存空间的浪费（如小分区队列满而大分区队列空）
	- 单队列：只有一个输入队列，进程使用可容纳它的最小空闲分区（无可用分区时可“交换”）
- 优缺点
	- 相对简单，开销小
	- 分区数目预设（系统创建时），限制了活动进程数
	- 分区大小预设，小作业不能充分利用其占有空间

####动态分区
- 系统运行中分区数目和大小均可以改变
	- 最初分区数为0，进程需要多少就给他分配多大分区
- 存在问题：外碎片
- 消除碎片：压缩——移动进程使相互紧靠（相当耗时，需动态重定位）
- 放置算法
	- 首次适配算法：从前端开始扫描内存，直到找到一个足够大的空闲区
	- 下次适配算法：从上次分配结束的地方开始扫描内存，直到找到一个足够大的空闲区
	- 最佳适配算法：扫描整个内存，找到一个足够大的最小空闲区
- 算法性能比较
	- 首次适配算法：简单，通常最好最快
	- 下次适配算法：稍差于首次适配，通常分配位于内存末端的那块空闲区，致使大块空闲区很快被分裂，因此需要经常压缩
	- 最佳适配算法：通常最差，产生大量无用碎片，导致需要更经常压缩

####伙伴系统
- 固定分区限制了活动进程的数量，内存空间利用率低
- 动态分区维护复杂，需要额外的压缩开销
- 折中方案----伙伴系统
	- 可用内存块的大小为2^k，L<=K<=U
		- 最小块为2^L
		- 最大块为2^U
	- 初始空间的大小为2^U的块
	- 若请求空间大小为s<2^(U-1），则对分现有块
	- 维护大小为2^K的所有空闲块的列表

####分区管理中的重定位

- 简单重定位
	- 多队列的不等长固定分区
	- 只需要在进程第一次载入时把其中的内存引用全换成绝对地址
- 动态重定位
	- 等长固定分区
	- 单队列的不等长固定分区
	- 动态分区
	- 压缩后

- 硬件机制
	- 寄存器
		- 基址寄存器
		- 界址寄存器
	- 地址转换
		- 计算物理地址
		- 安全检查

###页式存储管理
- 基本原理
	- 将主存划分为许多等长的小帧
	- 将进程划分为若干页，一个页的大小与一个帧大小相等
	- 进程加载时，所有页面被载入可用帧（不要求连续），同时建立页表----简单的分页主要数据结构

####页表
OS通过页表的建立和维护进行内存管理
- OS为每个进程建立并维护一个页表
- 页表的每个表项包含该页在内存中对应的帧号（还包括保护、共享等信息）
- 页表以页号为索引
- OS另外还维护一个空闲帧的列表

####简单分页中的重定位
- 程序中的逻辑地址由两部分组成
	- 页号
	- 页内偏移
- CPU的一对寄存器记录当前运行进程的页表起始物理地址，页表长度
- (页号,偏移)->(帧号,偏移)
- 规定：页（帧）的大小必须为2的整数次幂
- 当页（帧）的大小为2的m次幂时，逻辑地址与相对地址一致
- 16位编址，若页面大小为1K（1024），则需（低）10位表示页内偏移，剩下（高）6位表示页号，则
	- 相对地址1502的逻辑地址 = 1024+478 = (1,478)
	- 逻辑地址为(1,478)的相对地址 = 1\*1024+478 = 1502
- 页面大小为2的m次幂时，页面逻辑地址对程序员，编译器，汇编程序，链接程序都是透明的
- 动态地址转换硬件实现容易：(n,m)->(k,m) （查询页表，使页号n->k物理地址，偏移量还是偏移量）

####简单分页特点
- 类似固定分区，不同在于：
	- 分页中的“分区”（页帧）非常小（从而内碎片也小）
	- 分页中一个进程可占用多个“分区”（页帧）（从而也不需要覆盖）
	- 分页中不要求一个进程占用多个“分区”（页帧）连续（充分利用空闲“分区”）
- 存在问题
	- 不易实现共享和保护（不反映程序的逻辑组织）
	- 不便于动态链接（线性地址空间）
	- 不易处理数据结构的动态增长

###分段存储管理
基本原理
- 将程序及数据划分成若干段（不要求等长，但不能超过最大长度）
- 进程加载时，所有段被载入内存可用区域（不要求连续），同时建立段表

####段表
OS通过段表的建立和维护进行内存管理
- OS为每个进程建立并维护一个段表
- 段表的每个表项包含该段在内存中的起始物理地址、段长等
- 段表以段号为索引
- OS还另外维护一个内存空闲块的列表

####简单分段中的重定位
- 程序中的逻辑地址由两部分组成
	- 段号
	- 段内偏移
- 进程进入运行态时，其段表地址被载入CPU专用寄存器
- 逻辑地址(n,m)->物理地址的转换过程
	- 根据n位计算段号
	- 以段号为索引到段表查找得到段起始物理地址
	- 比较偏移（m位）与段长（据段表），若前者大，则非法
	- 物理地址 = 段起始地址+偏移

###页式管理与段式管理的比较
- 分页是出于系统管理的需要，分段是出于用户应用的需要
	- 一条指令或一个操作数可能会跨越两个页的分界处，二不会跨越两个段的分界处
- 页大小是固定的，但段大小不固定
- 逻辑地址表示
	- 分页是一维的，各个模块在链接时必须组织成一个地址空间
	- 分段是二维的，各个模块在链接时可以每个段组成一个地址空间
- 通常段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度
- 分段对程序员可见，从而可用来对程序和数据进行模块化组织
- 分段方便实现模块化共享和保护，如程序可执行、数据可读写

####动态分区管理和段式管理比较
- 都存在外碎片，但分段中可通过减少段长来减轻外碎片浪费程度
- 分段中一个进程可占用多个“分区”
- 分段不要求一个进程占用的多个“分区”连续（但要求一个段占用的多个“分区”连续）

####分页分段的主要优缺点
- 分段克服分页存在的问题（数据结构动态增长、动态链接、保护和共享等）
- 分段存在外碎片，分页只有小的内碎片，分页内存利用率比分段高

##虚拟存储器
###硬件和控制结构
####虚拟存储的关键基础
- 页式/段式存储管理的两大特点
	- 动态地址转换：进程中的逻辑地址在运行时动态转换成物理地址，从而进程可被交换出入内存，前后所占内存位置可以不同
	- 不连续分配：进程可分成几块，且这些块可分别存储到内存的不连续区域里
- 部分加载
运行时进程的所有页/段不必都在内存里，只要下一条要执行的指令和下一个要访问的数据在内存里即可

####部分加载方式与程序执行
- OS仅把程序起始点的一个或几个块装进内存
- 页表/段表表项中有一二进制位指示对应的块是否在内存中，进程中驻留在内存的部分称为驻留集
- 若遇到一个逻辑地址访问不在内存中的块，则产生一个访问内存错误的中断
- OS响应中断时将进程置于阻塞态，并将逻辑地址访问的块读入内存，过程
	- 发出一个磁盘I/O请求
	- 在执行I/O操作期间，分派另外一个进程运行
	- 磁盘I/O完成时产生一个中断，OS把受影响进程置于就绪队列

####部分加载与虚拟存储
- 采用部分加载，内存中可容纳更多的进程
	- 每个进程都只加载一部分，更多进程中应该也有更多的就绪进程，从而提高CPU使用率
- 采用部分加载，进程可以比内存大，实现了虚拟存储
	- 用户程序可以使用独立于物理内存的逻辑地址单元组成存储空间（虚拟存储）
	- 逻辑地址空间可以比物理地址空间大
	- 虚拟存储由内存和外存结合实现

####虚拟存储技术的特征
- 不连续性：物理内存分配的不连续
- 部分交换：与交换技术比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的
- 大空间：总容量不超过物理内存和外存交换区容量之和

####虚拟存储
- 实现模型：MMU存储管理单元，位于CPU

####程序局部性与虚拟存储
- 局部性原理
在一段时间内一个进程的运行往往呈现出高度局部性，表现为只运行某一段程序，只访问某一块数据区
- 空间局部性
观察程序在执行期间一个很短时间段内访问地址集合，可发现这些地址聚集在程序的某个局部区域中
- 时间局部性
观察程序的某些模块，通常可发现这些模块在程序运行期间只在某些很短的时间段被调用

- 虚拟存储管理的要求
	- 为了容纳更多进程，每个进程只有一小部分在内存中
	- 内存满时OS若要调用新的块，必须把内存中某一块换出去
	- OS必须在新的块用到之前就换入它

- 抖动问题
交换操作过于频繁，如将要用到的页是刚刚才被换出的，CPU更多时间是在处理交换而不是在执行命令（外存读写时间大于内存访问）

- 局部性原理保证了虚拟存储系统的可行性和效率性：
	- 内存可容纳更多进程
	- 可以避免由于交换进程中不被使用的部分而造成的时间浪费
	- 可有效避免抖动

####虚拟存储必要的支持
- 硬件支持：必须支持分页/分段所需的动态地址转换
- 软件支持
	- OS必须管理内存与外存间的页/段/段&页交换
	- 调页策略、放置策略、替换策略
	- 驻留集与工作集管理
	- 清除（回写）策略、加载（并发度）控制

###虚拟分页
####页表
- 页表项的一般内容
	- Present：在不在内存
	- Modified：是否被修改
	- Protection：保护码，1位或多位（rwe：读/写/执行）
	- Referenced：是否被访问
	- Cache：是否禁止缓存
- 页表长度不定，取决于进程大小
	- 不适合用寄存器存储页表，而是存放在内存
- 页表起始地址保存在一个CPU专用寄存器里

####页表与虚拟存储
- 页表占用的内存可能较大
- 可以对页表进行分页，存储到虚拟内存中
- 进程运行时它的部分页表必须在内存里（包括正在使用的页面对应的表项）
- 多级页表：既然一张页表通常需要几个页面来存储，一种页表的组织结构是多级层次，采用多级层次组织的页表称为多级页表

####多级页表
多级页表是一种多级层次组织结构
- 若采用二级页表，虚页号被划分为两个域：PT1和PT2
- 顶级页表（内存中）以PT1为索引，其表项指向二级页表，二级页表以PT2为索引
- 除顶级页表外其他页表可以在内外存间交换
- 对64位处理器，一般采用三级页表

####64位处理器与倒排页表
- 对64位CPU，若页面大小为4KB，则页表有2^52个表项，需占据大量存储空间
- 当物理内存远小于虚拟内存，在内存中创建包含所有虚拟存储空间的页帧对应的页表项，是不明智的
- 解决方案之一是采用倒排页表

- 实际内存中的每个页帧对应一个页表项（而不是每个虚拟内存的页面对应一个页表项）
- 页表项的内容：(进程ID,虚拟页面号)=(n,p)，记录定位于该页帧的进程和虚拟页面
- 优点：物理内存小时，倒排页表可大量节省空间
- 缺点：从虚拟地址转换到物理地址非常困难，不能使用CPU提供的页帧映射机制，需搜索整个倒排页表，查找对应于页表项(n,p)的页帧
- 解决办法：TBL和散列(Hash)表

####转换后备缓冲区TLB
- 页表存储在内存中致使每个内存引用只少访问两次内存，大大影响效率
- 设置特殊的硬件装置----TLB来对页表进行缓存（又称相连存储器）
- 存储少量最近最常用的页表表项
- 表项内容：有效位、虚页号、修改位、保护码、帧号等

####地址转换
- 使用TLB地址转换工作原理
	- 给定逻辑地址，CPU首先检查TLB，判断虚页号在不在其中
	- 若在，则直接从TLB提取帧号并形成物理地址
	- 若不在，则按普通方式访问页表工作，形成物理地址，更新TLB
- 不使用TLB地址转换工作原理
	- 由虚页号区页表检查该页在不在内存
	- 若在，形成物理地址
	- 若不在，产生页错误发出缺页中断，由OS将页面调入内存并更新页表，形成物理地址

####TLB中的细节
- 逻辑地址中虚页号与TLB表项的匹配检查由硬件实现，是并行的----关联映射
- TLB中每个表项的页号部分必须包含虚页号的所有域，只有整个虚页号匹配时才算命中
- TLB应随着进程的切换而刷新
	- 提供一条清除TLB中有效位的机器指令
	- 扩充TLB使包含一个进程标识域，同时增加一寄存器以保存当前进程标识符

####页面大小问题
- 页面大小是一个重要的硬件设计问题
	- 小页面有利于减小内碎片总量
	- 大页面有利于减小每进程的页表容量
	- 大页面有利于实现有效的磁盘数据块传送
- 最常用的页面大小介于1KB-8KB
- 有些处理器支持多种页面大小

####页面大小与缺页率
- 缺页率
	- 缺页次数/内存访问次数
	- 缺页的平均时间间隔
- 页面大小会影响缺页率
	- 页面很小：每个进程的内存页较多，通过调页很快适应局部性原理要求，缺页率低
	- 页面很大：进程使用的大部分地址空间都在内存，缺页率低
	- 页面中等大小：局部性区域只占每页较小部分，缺页率高

####页面大小与软件策略
- 页大小固定时，缺页率与分配给进程的内存页面数目的关系
	- 分配给进程的内存帧数可小于进程所需页面总数
	- 数目越多，缺页率越低
	- 页面数目的下限应该是一条指令及其操作数可能涉及的页面数
	- 页面数目的上限应该是足以保证进程每条指令都能被执行

####虚拟段式存储管理
- 段式管理的优点
	- 简化了动态增长的数据结构的处理
	- 支持模块的独立修改和重编译
	- 更有效的进程共享
	- 更容易实现保护
- 虚拟段式存储管理的组织
	- 段表：由表项组成，每个进程一张
	- 段表长度不定，存放在内存
	- 当前进程的段表起始地址保存在CPU的一个专用寄存器里
	- 进程中有的段可能不在内存中（位于外存）

####虚拟段页式存储管理
- 结合分页分段的优点，克服两者缺点
- 基本原理
	- 将程序按逻辑结构分成若干段，每个段划分为若干页
	- 将内存划分为许多小帧，帧与页大小相等
	- OS为每个进程建立维护一个段表，为每个段建立并维护一个页表
- 段表页表的表项分别类似虚拟段式、页式
	- 段表表项中的段起始地址是该段的页表起始地址
	- Present位和Modified位只含在页表表项中
	- 保护和共享位通常在段表表项中

- 程序中的逻辑地址(段号,页号,页内偏移)
- 逻辑地址中(n,p,d)，程序员可见段号n以及p和d构成的段内偏移，页号p及页内偏移d对程序员透明（假设页大小是2的m次幂）
- 地址转换：综合分页和分段

####共享和保护
- 共享
	- 不同进程间可以共享代码段和数据段
	- 实现：段表表项记录相同的段起始地址
- 保护
	- 越界保护（段基址&段长）
	- 访问方式保护（权限，如读写保护）
	- 环保护（模式&级别）

####环保护
- 分层访问模式：外到里----用户、管理、执行、内核
- 程序只能访问同层或更外层数据
- 程序可以调用同层或更内层的服务

###操作系统软件
- 设计时的三个基本选择问题
	- 是否支持虚存技术
	- 是否支持页式/段式/段页式（取决于硬件平台）
	- 采用的算法
- 软件设计的主要问题
	- 纯段式系统越来越少，段通常被分页，虚拟存储管理的主要问题主要就是虚拟页式存储管理问题
- 设计的目的
	- 使缺页率最小

###虚拟存储管理软件的各个方面
- 调页策略
- 放置策略
- 替换策略
- 驻留集和工作集管理
- 清除（回写）策略
- 负载（并发度）控制

####调页策略
- 决定何时页面载入内存
- 两种常用策略
	- 请求调页：只通过响应缺页中断调入需要的页面，也只调入发生缺页时所需要的页面
		- 进程开始运行时会有许多缺页，对外存I/O次数多，开销较大（一次I/O操作包括旋转等待时间和读写时间）
	- 预先调页：在发生缺页需要调入某页时，一次调入该页以及相邻的几个页
		- 提高调页的I/O效率
		- 效率不能保证：额外装入的页面可能没用

####放置策略
- 决定进程各个部分驻留在内存的哪个位置
- 对纯段式系统重要（似动态分区，涉及外碎片、压缩操作）
	- 最佳适配，首先适配
- 对纯页式或段页式系统不成问题
	- 不论放在哪里，其地址转换、内存存取都一样工作

####替换策略
- 需要调入页面而内存已满，决定置换（淘汰）内存中的哪个页面
- 经常要进行替换（为提高并发速度，OS总是载入尽量多的进程）
- 不是所有内存中的页面都可以被替换
	- 有些帧给锁定了：OS内核、关键控制结构、I/O缓冲区等
	- 驻留集策略决定了不同的替换范围：被替换的页面局限在本进程，或允许在其他进程

####基本替换算法
- 最优算法OPT
	- 淘汰“未来不再使用”或“还要最长时间才会使用”的那个页面
	- 效果最佳，但不可能实现
	- 可用作其他算法性能评价依据
- 最近最少使用算法LRU
	- 淘汰内存中最久未使用的页面
	- 性能接近最佳算法（局部性原理的合理近似）
	- 需要记录页面使用时间的先后关系，开销大
		- 链表：每次内存访问后在链表中找到对应的页面，把它移到表头，因此表尾就是最久未使用的
		- 硬件计数器：每执行一条指令计数器就加1，每次内存访问后将当前计数器的值写到相应的内表表项里，计数器值最小的就是最久未使用的。
- 先进先出算法FIFO
	- 淘汰内存中建立最早的页面
	- 实现简单，可通过链表来表示各页建立时间先后，新来的到表尾，表头就是最老的
	- 性能差
		- 较早调入的页往往是经常被访问的页，这些页在FIFO算法下被反复调入调出
		- 有Belady现象，在分页式虚拟存储器管理中，缺页置换算法采用FIFO算法时，如果对一个进程未分配它所要求的全部页面，有时会出现分配的页面数增多缺页率反而提高的异常现象。
- 时钟算法
	- 性能近似LRU，实现开销小于LRU
	- 环形链表实现算法
		- 环形链表头尾相邻，因此只需移动一个指针
		- 每页关联一个使用位R
			- 每次读一个页，处理完毕之后将R置为1
			- 在替换算法扫描后，置R为0
		- 当需要替换页时，从指针当前位置开始扫描整个缓冲区，遇到第一个使用位为0的进行替换。

####驻留集管理
- 每次给进程分配多少物理页面，以及如何动态调整个进程的物理页面数
- 驻留集指虚拟也是存储管理中给进程分配的物理页面（帧）的集合，驻留集大小即是这个集合的元素个数

#####驻留集大小与系统效率
- 每个进程的驻留集越小，同时驻留内存的进程就越多，CPU利用率越高
- 进程驻留集太小的话，缺页率高，调页开销增大
- 驻留集大小到达一定数目后，再给他分配更多页面，缺页率不明显下降

#####管理策略
- 固定分配：在执行的过程中驻留集大小固定
	- 各个进程驻留集大小在进程创建时决定，可根据进程类型，或由程序员、系统管理员决定
	- 替换页面可从各自驻留集中选择
- 可变分配：在执行过程中进程驻留集大小可变
	- 可根据缺页率动态调整，性能较好
	- 需要OS对活动进程行为进行评估，增加开销

#####替换范围
- 全局替换：内存中任意非锁定页面均可替换
- 局部替换：被替换的页面局限在缺页进程的驻留集
	- 容易进行性能分析
	- 性能不一定比全局替换好

#####可变分配加局部替换
- 具体做法
	- 进程加载进内存时，给它分配一定数目的物理页面，采用请求调页或预先调页填满这些页面
	- 缺页时，从缺页进程本身的驻留集选择替换一页面
	- 定期重新评估进程驻留集大小，并响应增加或减小，以提高系统整体性能
- 比简单的全局替换复杂，但性能好
- 以工作集策略来调整驻留集大小

####工作集
- 引入工作集的目的是根据进程过去一段时间内访问的页面的来调整驻留集大小
- 工作集时一个进程执行过程中某段时间访问的页面集合，用二元函数$W(t,\Delta)$表示：
	- t是执行时刻
	- $\Delta$是一个虚拟时间段，称为窗口大小，它采用虚拟时间单位（即实际执行时间，阻塞时不计时）可用执行的指令数目或处理器执行时间来计算
	- 工作集是$[t-\Delta,t]$虚拟时间段内访问的页面的集合，$|W(t,\Delta)|$指工作集大小，即页面数目

#####工作集大小变化
- 进程开始执行时，随着访问新页面增大
- 当内存访问的局部性区域的位置大致稳定时，工作集大小也大致稳定
- 局部性区域的位置改变时，工作集快速扩张和收缩过度到下一个稳定值

#####工作集性质
- 随$\Delta$单调递增
$W(t,\Delta)\inW(t,\Delta+a)$，其中$a>0$
- 工作集大小范围$1<=|W(t,\Delta)|<=min(\Delta,N)$，其中N是进程总页面数

#####工作集策略
- 利用工作集来进行驻留集管理的策略
	- 记录一个进程的工作集变化
	- 定期删除驻留集中不在工作集中的页面
	- 总是让驻留集包含工作集（不能包含时增大驻留集）
- 存在问题
	- 过去未必能预示将来
	- 记录每个进程的工作集变化开销大
	- 对工作集窗口大小$\Delta$的最优值难以确定，而且通常该值是不断变化的

#####工作集策略的接近策略
- 缺页率算法PPF：跟踪缺页率而不是工作集的变化
	- 设定缺页率高低阈值，超出时增大或减小驻留集大小
	- 主要缺点：在局部性阶段过渡期间效果不好
- 可变间隔采样工作集VSWS策略
	- 通过增加采样频率解决PPF算法缺点
	- 驱动参数：采样区间的最大/最小宽度M/L（为异常条件提供边界保护）、采样实例间允许发生的缺页中断数Q（使能正常激活采样）
	- 策略：
		- 采样间隔达到L时挂起进程扫描使用位
		- 若在采样间隔<L时发生了Q次缺页中断：
			- <M，一直等待
			- >=M，扫描使用位

####清除策略
- 决定何时将已修改页面调出到外存
- 两种常用策略：
	- 请求清除：该页被置换之前才调出，即把清除推迟到最后
		- 调入所缺页面前还要调出已修改页面，缺页进程等待时间长
	- 预先清除，该页被置换前酒店出，因而可以成批调出多个页面
		- 若这批调出外存的页面中多数被置换之前还要再修改，意义不大

####负载控制
- 决定内存中同时驻留的数目
	- 太少，则所有进程可能都处于阻塞态，CPU空闲时间多
	- 太多，每个进程驻留集小，缺页频繁发生，导致“抖动”

#####负载控制策略
- 基于工作集策略的算法（PFF）
	- 他们隐含负载控制策略，只有那些驻留集足够大的进程才能运行，实现对负载的自动和动态控制
- “L=S判据”策略
	- 让缺页平均间隔时间（指真实时间而不是虚拟时间）等于对每次缺页的处理时间，研究表明这时对CPU利用率最大
	- 类似的50%判据策略：让外存交换设备保持50%利用率，对CPU利用率最高

####加载控制策略
- 基于Clock替换算法的加载控制策略
- 定义一个轮转计数，描述轮转的速率
- 当轮转计数小于一定阈值时，表明缺页较少或存在较多不常使用的页面，提高系统负载
- 当轮转计数大于某阈值时，表明系统的进程并发水平过高，需降低系统负载

#####加载控制的实施
- 当系统并发水平高时，需降低负载
- OS不能完全控制进程创建，但可通过进程挂起来减少驻留内存的进程数
	- 即，需要减少驻留内存的进程数目时。可以将部分进程挂起并全部换出到外存上。如低优先级的、缺页率高的、驻留集最小的、页面最多的，等等

##单处理器调度
###处理器调度的类型
- 长程调度
	- 决定哪些新建进程可进入系统准备执行
	- 控制多道程序系统的并发程度
	- 进程越多则各进程对CPU的使用百分比越小
- 中程调度
	- 决定交换哪些主存-辅存（内存-外存）进程
	- 基于多道程序设计的管理需要
- 短程调度
	- 决定下一个使用CPU的进程
- I/O调度
	- 决定可用的I/O设备处理哪个进程挂起的I/O请求

####调度与进程状态转换
调度队列（P5）比较重要！

####短程调度时机
- 当前进程正常或异常终止（通过中断实现）
- 时钟或I/O中断
- 系统调用（通过软中断实现）
- 信号量操作（通过软中断实现）

####短程调度模式
- 非剥夺式
	- 让进程运行直到结束或阻塞的调度方式
	- 容易实现
	- 适合专用系统，不适合通用系统
- 剥夺式
	- 允许将逻辑上可继续运行的进程在运行过程中暂停的调度方式
	- 可防止单一进程长时间独占CPU
	- 系统开销大（降低：硬件实现进程切换，或扩充主存以贮存大部分程序）

####短程调度过程
- 进程上下文切换过程
- 基本过程
	- 保存现场
	- 据某调度算法选择下一个要运行的进程，如果没有就绪进程，系统会安排一个空闲进程，没有其他进程时该进程一直运行，执行过程中接收中断
	- 恢复现场

####短程调度目标
- 面向用户的目标与面向系统的目标
- 定量目标与定性目标
- 主要目标
	- 公平——确保每个进程都获得合理的CPU份额
	- 效率——使CPU及其他系统资源尽量忙碌
	- 响应时间（提交——开始输出结果）——尽可能短
	- 周转时间/驻留时间（从提交到结束）——尽可能短
	- 吞吐量（单位时间完成进程数）——尽可能大
	- 实时性——可以指定进程完成的最后期限

###进程调度算法
####先来先服务（FCFS）
- 当前进程结束后，选择最早到达就绪队列的那个进程（非剥夺式）
- 短进程等待执行的时间可能相当长
- I/O密集进程必须等待CPU密集进程结束

####最短进程优先（SPN）
- 每次调度选取估计运行时间最短的进程
- 不可剥夺式（不适合分时和事务处理系统）
- 长进程可能被饿死
- 难点：预知或估计进程执行时间
	- 生产环境：统计
	- 交互式环境：估计
- 指数平滑技术
$$S_{n+1}=aT_n+(1-a)S_n$$
$S_n$：第n个实例执行时间估计值
$T_n$：第n个实例执行时间测量值

####最短剩余优先（SRT）
- 剥夺式SPN
	- 新进程进入就绪队列时将重新引发调度
	- 选取估计剩余时间最短的进程
- 需要估计进程剩余执行时间
- 长进程可能饿死

####最高响应比优先（HRRN）
- 非剥夺式
- 每次调度选取响应比R最大的进程
	- w：等待CPU时间
	- s：估计执行时间
	- $R=\frac{w+s}{s}$
- 利短进程，但长进程也不会饿死
- 同SRN、SRT，要估计执行时间

####时间片轮转（RR）
- 剥夺式FCFS
	- 把CPU划分为若干时间片，并按顺序分配个就绪队列的各个进程
	- 时间片用完而当前进程尚未结束时，系统剥夺进程CPU，将进程排列到就绪队列的末尾，同时选择就绪队列头的进程运行
- 时间片长度选择问题：
	- 太短：切换开销大
	- 太长：响应时间变长
	- 一般比典型的一次交互过程时间略长
- 分时系统和事务处理系统常用时间片轮转
- 利CPU密集进程，不利I/O密集进程

####虚拟轮转（VRR）
- 阻塞解除的进程进入辅助队列
- 辅助队列中的进程比就绪队列的进程优先获得处理器
- 可解决轮转对I/O密集进程不公平的问题

####最高优先级优先
- 每个进程被赋予一个优先级，每次调度选取就绪队列中优先级最高的进程投入运行
- 优先级确定方法
	- 静态：进程创建时指定优先级，在进程运行时优先级保持不变
	- 动态：在进程创建时指定一个优先级，但在其生命周期中优先级可动态变化（如等待时间长的优先级可提高，时间片过后优先级降低）
	- 实现时可对应不同优先级采用多个就绪队列

####多级队列反馈
- 剥夺式、时间片
- 关注进程已执行时间，不用估计剩余执行时间
- 思想：采用动态优先级机制
	- 设立多个优先级就绪队列，各个队列运行时间片可能不同（优先级越高[i越小]时间片越小$2^i$）
	- 新的就绪进程进入最高优先级队列
	- 进程由于时间片用完被抢占而放弃CPU，下降一个优先级队列（最高->最低）
	- 进程由于等待而放弃CPU后，进程等待队列，一旦等待的时间发生，则回到原来的就绪队列
	- 各优先级队列使用FCFS（最低用RR）
- 调度：先按FCFS从最高优先级队列选取，若空则次高

####性能比较
- 短进程（高优先级）的标准化响应时间
	- 归一化响应时间：周转时间/平均服务时间=1/(1-处理器利用率)
- 长进程

####公平共享调度
- 用户应用或作业可以是一个进程（线程）集合，而用户关心的是作业或应用的整体性能，因此应基于进程集合进行调度决策
- 一个用户也可以看作是用户组的成员，同一用户组的用户应只影响本用户组的调度，不该影响其他用户组的调度，即应基于用户组进行调度决策
- 公平共享调度（FSS）：基于组调度，每个组公平共享处理器时间
	- 每个用户被指定某种类型的权值，以定义其使用共享资源的份额
实例：p31

进程j在时间段i开始处优先级
$$P_j(i)=Base_j+CPU_j(i)/2+GCPU_j(i)/4W_k$$
其中：
1. 进程j的基础优先级$Base_j=60$
2. 进程j在时间段i中处理器使用计数$CPU_j(i)=CPU_j(i-1)/2$
3. 组j在时间段i中处理器使用计数$GCPU_j(i)=GCPU_j(i-1)/2$
4. 分配给组k的权值$W_k=0.5$

####各种调度策略的特点


| 类别   | 先来先服务FCFS | 轮转RR    | 最短进程优先SPN  | 最短剩余优先SRT  | 最高响应比优先HRRN  | 反馈MF/FB    |
|:----  |:-------------|:--------|:--------------|:-------------|:-----------------|:-----------|
| 选择函数| max(w)       | 常数     | min(s)          | min(s-e)     | max((w+s)/s)      | e，优先级    |
| 决策模式| 非抢占       | 抢占（时间片） | 非抢占         | 抢占（到达时）   | 非抢占            | 抢占（时间片）  |
| 吞吐量  | 不强调       | 时间片太小时会低 | 高          | 高             | 高               | 不强调      |
| 响应时间| 可能大       | 短进程小     | 短进程小        | 小             | 小               | 不强调      |
| 开销   | 最小        | 最小        | 可能高          | 可能高         | 可能高            | 可能高      |
| 对进程影响  | 对短进程和I/O密集进程不利 | 公平对待 | 对长进程不利 | 对长进程不利 | 很好的平衡| 可能对I/O密集型进程有利 |
| 饥饿    | 无        | 无        | 可能          | 可能         | 无            | 可能      |

##输入输出与磁盘调度
###I/O特点
- I/O性能经常成为系统性能的瓶颈
- I/O是导致操作系统庞大复杂的原因之一
	- 种类繁多、结构各异、速度差异大
- 理解I/O的工作过程与结构是理解操作系统的工作过程与结构的关键
- 与操作系统的其他功能（文件系统）联系密切







